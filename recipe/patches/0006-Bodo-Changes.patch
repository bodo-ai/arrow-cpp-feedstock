diff --git a/cpp/CMakePresets.json b/cpp/CMakePresets.json
index 13d1241990..cb64601b6f 100644
--- a/cpp/CMakePresets.json
+++ b/cpp/CMakePresets.json
@@ -182,6 +182,21 @@
         "ARROW_ORC": "ON"
       }
     },
+    {
+      "name": "features-python-bodo",
+      "inherits": [
+        "features-filesystems",
+        "features-flight-sql",
+        "features-gandiva",
+        "features-main",
+        "features-python-minimal"
+      ],
+      "hidden": true,
+      "cacheVariables": {
+        "ARROW_ORC": "ON",
+        "PARQUET_REQUIRE_ENCRYPTION": "ON"
+      }
+    },
     {
       "name": "features-python-maximal",
       "inherits": [
@@ -430,6 +445,15 @@
       "displayName": "Release build for PyArrow with common features (for backward compatibility)",
       "cacheVariables": {}
     },
+    {
+      "name": "ninja-release-python-bodo",
+      "inherits": [
+        "base-release",
+        "features-python-bodo"
+      ],
+      "displayName": "Release build for PyArrow with everything required for Bodo",
+      "cacheVariables": {}
+    },
     {
       "name": "ninja-release-python-maximal",
       "inherits": [
@@ -491,4 +515,4 @@
       }
     }
   ]
-}
\ No newline at end of file
+}
diff --git a/cpp/src/arrow/dataset/file_parquet.cc b/cpp/src/arrow/dataset/file_parquet.cc
index c17ba89be7..15bde86ba4 100644
--- a/cpp/src/arrow/dataset/file_parquet.cc
+++ b/cpp/src/arrow/dataset/file_parquet.cc
@@ -36,6 +36,7 @@
 #include "arrow/util/iterator.h"
 #include "arrow/util/logging.h"
 #include "arrow/util/range.h"
+#include "arrow/util/thread_pool.h"
 #include "arrow/util/tracing_internal.h"
 #include "parquet/arrow/reader.h"
 #include "parquet/arrow/schema.h"
@@ -630,10 +631,15 @@ Result<RecordBatchGenerator> ParquetFileFormat::ScanBatchesAsync(
             kParquetTypeName, options.get(), default_fragment_scan_options));
     int batch_readahead = options->batch_readahead;
     int64_t rows_to_readahead = batch_readahead * options->batch_size;
-    ARROW_ASSIGN_OR_RAISE(auto generator,
-                          reader->GetRecordBatchGenerator(
-                              reader, row_groups, column_projection,
-                              ::arrow::internal::GetCpuThreadPool(), rows_to_readahead));
+    // Modified this to pass the executor in scan_options instead of always using the
+    // default CPU thread pool.
+    // XXX Should we get it from options->fragment_scan_options instead??
+    auto cpu_executor = options->exec_context.executor()
+                            ? options->exec_context.executor()
+                            : ::arrow::internal::GetCpuThreadPool();
+    ARROW_ASSIGN_OR_RAISE(auto generator, reader->GetRecordBatchGenerator(
+                                              reader, row_groups, column_projection,
+                                              cpu_executor, rows_to_readahead));
     RecordBatchGenerator sliced =
         SlicingGenerator(std::move(generator), options->batch_size);
     if (batch_readahead == 0) {
diff --git a/cpp/src/arrow/dataset/scanner.cc b/cpp/src/arrow/dataset/scanner.cc
index 18981d1451..cdf5f586b4 100644
--- a/cpp/src/arrow/dataset/scanner.cc
+++ b/cpp/src/arrow/dataset/scanner.cc
@@ -302,6 +302,7 @@ Result<EnumeratedRecordBatchGenerator> FragmentToBatches(
                  {"arrow.dataset.fragment.type_name", fragment.value->type_name()},
              });
 #endif
+  // This is the call site.
   ARROW_ASSIGN_OR_RAISE(auto batch_gen, fragment.value->ScanBatchesAsync(options));
   ArrayVector columns;
   for (const auto& field : options->dataset_schema->fields()) {
@@ -327,6 +328,7 @@ Result<EnumeratedRecordBatchGenerator> FragmentToBatches(
 Result<AsyncGenerator<EnumeratedRecordBatchGenerator>> FragmentsToBatches(
     FragmentGenerator fragment_gen, const std::shared_ptr<ScanOptions>& options) {
   auto enumerated_fragment_gen = MakeEnumeratedGenerator(std::move(fragment_gen));
+  // This is the call-site.
   auto batch_gen_gen =
       MakeMappedGenerator(std::move(enumerated_fragment_gen),
                           [=](const Enumerated<std::shared_ptr<Fragment>>& fragment) {
@@ -353,8 +355,10 @@ class OneShotFragment : public Fragment {
     ARROW_ASSIGN_OR_RAISE(
         auto background_gen,
         MakeBackgroundGenerator(std::move(batch_it_), options->io_context.executor()));
-    return MakeTransferredGenerator(std::move(background_gen),
-                                    ::arrow::internal::GetCpuThreadPool());
+    auto cpu_executor = options->exec_context.executor()
+                            ? options->exec_context.executor()
+                            : ::arrow::internal::GetCpuThreadPool();
+    return MakeTransferredGenerator(std::move(background_gen), cpu_executor);
   }
   std::string type_name() const override { return "one-shot"; }
 
@@ -380,7 +384,7 @@ Result<TaggedRecordBatchIterator> AsyncScanner::ScanBatches() {
       [this](::arrow::internal::Executor* executor) {
         return ScanBatchesAsync(executor);
       },
-      scan_options_->use_threads);
+      scan_options_->use_threads, this->async_cpu_executor());
 }
 
 Result<EnumeratedRecordBatchIterator> AsyncScanner::ScanBatchesUnordered() {
@@ -388,7 +392,7 @@ Result<EnumeratedRecordBatchIterator> AsyncScanner::ScanBatchesUnordered() {
       [this](::arrow::internal::Executor* executor) {
         return ScanBatchesUnorderedAsync(executor);
       },
-      scan_options_->use_threads);
+      scan_options_->use_threads, this->async_cpu_executor());
 }
 
 Result<std::shared_ptr<Table>> AsyncScanner::ToTable() {
@@ -398,7 +402,7 @@ Result<std::shared_ptr<Table>> AsyncScanner::ToTable() {
 }
 
 Result<EnumeratedRecordBatchGenerator> AsyncScanner::ScanBatchesUnorderedAsync() {
-  return ScanBatchesUnorderedAsync(::arrow::internal::GetCpuThreadPool(),
+  return ScanBatchesUnorderedAsync(this->async_cpu_executor(),
                                    /*sequence_fragments=*/false);
 }
 
@@ -443,6 +447,7 @@ Result<EnumeratedRecordBatchGenerator> AsyncScanner::ScanBatchesUnorderedAsync(
                    scan_options_->projection.call()->options.get())
                    ->field_names;
 
+  // This is where the node is added to the plan.
   RETURN_NOT_OK(
       acero::Declaration::Sequence(
           {
@@ -599,11 +604,12 @@ Result<std::shared_ptr<Table>> AsyncScanner::Head(int64_t num_rows) {
 }
 
 Result<TaggedRecordBatchGenerator> AsyncScanner::ScanBatchesAsync() {
-  return ScanBatchesAsync(::arrow::internal::GetCpuThreadPool());
+  return ScanBatchesAsync(this->async_cpu_executor());
 }
 
 Result<TaggedRecordBatchGenerator> AsyncScanner::ScanBatchesAsync(
     Executor* cpu_executor) {
+  // Is this part of the code path?
   ARROW_ASSIGN_OR_RAISE(
       auto unordered, ScanBatchesUnorderedAsync(cpu_executor, /*sequence_fragments=*/true,
                                                 /*use_legacy_batching=*/true));
@@ -775,7 +781,7 @@ Future<int64_t> AsyncScanner::CountRowsAsync(Executor* executor) {
 }
 
 Future<int64_t> AsyncScanner::CountRowsAsync() {
-  return CountRowsAsync(::arrow::internal::GetCpuThreadPool());
+  return CountRowsAsync(this->async_cpu_executor());
 }
 
 Result<int64_t> AsyncScanner::CountRows() {
@@ -999,6 +1005,7 @@ Result<acero::ExecNode*> MakeScanNode(acero::ExecPlan* plan,
   ARROW_ASSIGN_OR_RAISE(auto fragments_vec, fragments_it.ToVector());
   auto fragment_gen = MakeVectorGenerator(std::move(fragments_vec));
 
+  // This is the call site.
   ARROW_ASSIGN_OR_RAISE(auto batch_gen_gen,
                         FragmentsToBatches(std::move(fragment_gen), scan_options));
 
@@ -1168,6 +1175,7 @@ Result<acero::ExecNode*> MakeOrderedSinkNode(acero::ExecPlan* plan,
 
 namespace internal {
 void InitializeScanner(arrow::acero::ExecFactoryRegistry* registry) {
+  // This is where it's registered.
   DCHECK_OK(registry->AddFactory("scan", MakeScanNode));
   DCHECK_OK(registry->AddFactory("ordered_sink", MakeOrderedSinkNode));
   DCHECK_OK(registry->AddFactory("augmented_project", MakeAugmentedProjectNode));
diff --git a/cpp/src/arrow/dataset/scanner.h b/cpp/src/arrow/dataset/scanner.h
index 4479158ff2..301cdc0517 100644
--- a/cpp/src/arrow/dataset/scanner.h
+++ b/cpp/src/arrow/dataset/scanner.h
@@ -107,6 +107,11 @@ struct ARROW_DS_EXPORT ScanOptions {
   /// Note: The IOContext executor will be ignored if use_threads is set to false
   io::IOContext io_context;
 
+  /// ExecContext for any CPU tasks
+  ///
+  /// Note: The ExecContext executor will be ignored if use_threads is set to false
+  compute::ExecContext exec_context;
+
   /// If true the scanner will scan in parallel
   ///
   /// Note: If true, this will use threads from both the cpu_executor and the
@@ -437,6 +442,11 @@ class ARROW_DS_EXPORT Scanner {
       TaggedRecordBatchIterator scan);
 
   const std::shared_ptr<ScanOptions> scan_options_;
+
+  ::arrow::internal::Executor* async_cpu_executor() const {
+    return scan_options_->exec_context.executor() ? scan_options_->exec_context.executor()
+                                                  : ::arrow::internal::GetCpuThreadPool();
+  }
 };
 
 /// \brief ScannerBuilder is a factory class to construct a Scanner. It is used
diff --git a/cpp/src/arrow/util/thread_pool.h b/cpp/src/arrow/util/thread_pool.h
index 44b1e227b0..218edc60ca 100644
--- a/cpp/src/arrow/util/thread_pool.h
+++ b/cpp/src/arrow/util/thread_pool.h
@@ -20,6 +20,7 @@
 #include <cstdint>
 #include <memory>
 #include <queue>
+#include <thread>
 #include <type_traits>
 #include <unordered_set>
 #include <utility>
@@ -591,6 +592,21 @@ typename Fut::SyncType RunSynchronously(FnOnce<Fut(Executor*)> get_future,
   }
 }
 
+template <typename T>
+Iterator<T> IterateSynchronously(
+    FnOnce<Result<std::function<Future<T>()>>(Executor*)> get_gen, bool use_threads,
+    Executor* executor) {
+  if (use_threads) {
+    auto maybe_gen = std::move(get_gen)(executor);
+    if (!maybe_gen.ok()) {
+      return MakeErrorIterator<T>(maybe_gen.status());
+    }
+    return MakeGeneratorIterator(*maybe_gen);
+  } else {
+    return SerialExecutor::IterateGenerator(std::move(get_gen));
+  }
+}
+
 /// \brief Potentially iterate an async generator serially (if use_threads is false)
 /// \see IterateGenerator
 ///
@@ -605,15 +621,7 @@ typename Fut::SyncType RunSynchronously(FnOnce<Fut(Executor*)> get_future,
 template <typename T>
 Iterator<T> IterateSynchronously(
     FnOnce<Result<std::function<Future<T>()>>(Executor*)> get_gen, bool use_threads) {
-  if (use_threads) {
-    auto maybe_gen = std::move(get_gen)(GetCpuThreadPool());
-    if (!maybe_gen.ok()) {
-      return MakeErrorIterator<T>(maybe_gen.status());
-    }
-    return MakeGeneratorIterator(*maybe_gen);
-  } else {
-    return SerialExecutor::IterateGenerator(std::move(get_gen));
-  }
+  return IterateSynchronously(std::move(get_gen), use_threads, GetCpuThreadPool());
 }
 
 }  // namespace internal
diff --git a/cpp/src/parquet/arrow/reader.cc b/cpp/src/parquet/arrow/reader.cc
index d6ad7c25bc..5ade5bb747 100644
--- a/cpp/src/parquet/arrow/reader.cc
+++ b/cpp/src/parquet/arrow/reader.cc
@@ -1153,6 +1153,7 @@ class RowGroupGenerator {
       const int row_group, const std::vector<int>& column_indices) {
     // Skips bound checks/pre-buffering, since we've done that already
     const int64_t batch_size = self->properties().batch_size();
+    // This the main location.
     return self->DecodeRowGroups(self, {row_group}, column_indices, cpu_executor)
         .Then([batch_size](const std::shared_ptr<Table>& table)
                   -> ::arrow::Result<RecordBatchGenerator> {
@@ -1190,6 +1191,7 @@ FileReaderImpl::GetRecordBatchGenerator(std::shared_ptr<FileReader> reader,
                        reader_properties_.cache_options());
     END_PARQUET_CATCH_EXCEPTIONS
   }
+  // This is where it's created it seems.
   ::arrow::AsyncGenerator<RowGroupGenerator::RecordBatchGenerator> row_group_generator =
       RowGroupGenerator(::arrow::internal::checked_pointer_cast<FileReaderImpl>(reader),
                         cpu_executor, row_group_indices, column_indices,
@@ -1228,6 +1230,7 @@ Status FileReaderImpl::ReadRowGroups(const std::vector<int>& row_groups,
     END_PARQUET_CATCH_EXCEPTIONS
   }
 
+  // This is another call site (might not be called by our use case).
   auto fut = DecodeRowGroups(/*self=*/nullptr, row_groups, column_indices,
                              /*cpu_executor=*/nullptr);
   ARROW_ASSIGN_OR_RAISE(*out, fut.MoveResult());
@@ -1249,6 +1252,7 @@ Future<std::shared_ptr<Table>> FileReaderImpl::DecodeRowGroups(
                                               std::shared_ptr<ColumnReaderImpl> reader)
       -> ::arrow::Result<std::shared_ptr<::arrow::ChunkedArray>> {
     std::shared_ptr<::arrow::ChunkedArray> column;
+    // This is the most likely place for invocation.
     RETURN_NOT_OK(ReadColumn(static_cast<int>(i), row_groups, reader.get(), &column));
     return column;
   };
